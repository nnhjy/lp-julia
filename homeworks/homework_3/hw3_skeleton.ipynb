{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MS-E2121 - Linear Optimization\n\n## Homework 3"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using LinearAlgebra"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Revised simplex\nThe following cell contains all the functions that are used in our implementation of the revised simplex method. Your task is to implement the functions by replacing the \"TODO: add your code here\" -comments with your code."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Dictionary of elements:\n#     A: The constraint matrix\n#     b: The RHS (right-hand side) vector\n#     B_hist: Column indices of the basic variables at each iteration\n#     B_ind: The column indices of the basic variables\n#     c: The vector of cost coefficients\n#     cᵣ: The vector of reduced costs\n#     c_hist: Reduced costs at each iteration\n#     I: contains the row indices of u for which its components are positive    \n#     iter:   Number of iterations so far\n#     J: set of indices of nonbasic variables that are candidate to become basic (with cᵣ < 0)\n#     j_in: index of the nonbasic variable selected to become basic\n#     l_out: the index of the basic variable selected to become nonbasic  \n#     rule: the pivoting rule for choosing the entering variable. Options are :bland and :dantzig \n#     u: the reverse of the basic directions \n#     x_hist: Decision variable values at each iteration\n\n## Update \"history arrays\"\nfunction update_history!(c_hist, cᵣ, x_hist, x, B_hist, B_ind, iter)\n    c_hist[iter,:] = cᵣ\n    x_hist[iter,:] = x\n    B_hist[iter,:] = B_ind\nend\n\n## Return true if the while-loop should continue, \n## false if optimal solution has been obtained\nfunction iteration_condition(cᵣ, ϵ)\n    return !all(cᵢ>=-ϵ for cᵢ in cᵣ)\nend\n\n## Calculate the reduced costs cᵣ (Hint: you might want to calculate p, the vector of dual variables, \n## but it doesn't need to be returned as it is not used in other parts of the algorithm)\nfunction calculate_cr(A, c, B_ind, invB)\n    # TODO: add your code here\nend\n\n## Choose the variable with the smallest column index in accordance with predefined rule\nfunction select_entering_variable(J, cᵣ, rule)\n    if rule == :dantzig   # Dantzig's rule: most negative reduced cost\n        # TODO: add your code here\n    elseif rule == :bland # Bland's rule: smallest index j    \n        # TODO: add your code here\n    end\n    return j_in\nend\n\n## Compute the vector u (i.e., the reverse of the basic directions)\nfunction calculate_reverse_basic_directions(A, invB, j_in)\n    # TODO: add your code here\nend\n\n## Compute the optimal step length θ by performing element-wise\n## divisions (./) between the vector x(B_ind) of basic variables and the vector\n## u. The divisions are performed only for the elements of u and x(B_ind(I))\n## with indices in I (I contains the row indices of u for which\n## u(I) is positive). The corresponding basic variables are in vector x(B_ind(I)).\n## The minimum of these element-wise divisions is the optimal step length.\nfunction calculate_step_length(x, B_ind, u, I) \n    # TODO: add your code here\nend\n\n## Select the smallest (row) index among the potential exiting variables in\n## accordance with Bland's rule (minimum index) and store it to l_out\n## Hint: First find the row indices of all the basic variables with the optimal step length θ\n## by performing element-wise divisions (./) between the vector of basic\n## variables x(B_ind) and the vector u and checking if the step equals θ.\n## This set (of those indices for which the step is equal to θ) then contains all the basic row indices \n## with the optimal step length (i.e., the row indices of the basic variables that can exit the basis)\nfunction select_leaving_variable(B_ind, x, u, I, θ)\n    # TODO: add your code here\n    return l_out\nend\n\n## Move to the adjacent solution (move in direction -u with the optimal step \n## length θ): x(B) = x(B) - θ*u    AND   x(j) = 0 + θ\n## NOTE: The exclamation mark is a naming convention for a mutating function,\n## that is, a function that modifies its input variables and doesn't necessarily return anything\n## See for example the function update_history! above\nfunction update_x!(x, j_in, B_ind, θ, u)\n    # TODO: add your code here\nend\n\n## Update the set of basic indices (replace the index of the leaving\n## variable l_out with that of the entering variable j_in)\nfunction update_B_ind!(B_ind, l_out, j_in)\n    # TODO: add your code here\nend\n\n## Compute the new inverse basis B^-1 by performing elementary row\n## operations on [B^-1 u] (pivot row index is l_out, the vector u is trans-\n## formed into a unit vector with u(l_out) = 1 and u(i) = 0 for other i).\nfunction update_invB!(invB, u, l_out)\n    # TODO: add your code here\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the functions defined above, we can implement another function for running a single iteration of the revised simplex algorithm."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function revised_simplex_iteration(A, c, B_ind, x, cᵣ, invB, rule, ϵ)\n    ## Find all variables with negative reduces costs; the column indices j\n    ## of these variables are stored in vector J\n    J = findall(vec(cᵣ) .< -ϵ)  ## We use vec(c_r) since findall is type sensitive and might return CartesianIndices instead.\n\n    j_in = select_entering_variable(J, cᵣ, rule)\n\n    u = calculate_reverse_basic_directions(A, invB, j_in)\n\n    ## Find all row indices, stored in vector I, for which the elements of u\n    ## are positive.\n    I = findall(vec(u) .> ϵ)\n\n    ## In case no element of u is positive (i.e., I is empty), the problem\n    ## is unbounded and the optimal cost is -infinity\n    ## The final return parameter is a flag telling the main function the outcome of \n    ## this iteration: -1 for unboundedness, 1 for successfully finishing the iteration\n    if (isempty(I))\n        return B_ind, x, cᵣ, invB, -1\n    end\n\n    θ = calculate_step_length(x, B_ind, u, I)\n\n    l_out = select_leaving_variable(B_ind, x, u, I, θ)\n\n    update_x!(x, j_in, B_ind, θ, u)\n\n    update_B_ind!(B_ind, l_out, j_in)\n\n    update_invB!(invB, u, l_out)\n    \n    cᵣ = calculate_cr(A, c, B_ind, invB)\n    \n    return B_ind, x, cᵣ, invB, 1\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell contains the function for the revised simplex method. You do not need to change anything here, but it might be good to understand the main idea of the code nevertheless."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Revised Simplex\n\n# Naive implementation of the primal revised Simplex. Solves a linear\n# programming problem of the form\n#\n#   min c'x\n#   s.t. Ax  = b\n#         x >= 0\n#\n# The function input parameters are the following:\n#     A: The constraint matrix\n#     b: The RHS (right-hand side) vector\n#     c: The vector of cost coefficients\n#     B_ind: The column indices of the basic variables corresponding to an\n#        initial basic feasible solution\n#     rule: an optional keyword argument defining the pivoting rule for \n#        choosing the entering variable. Options are :bland and :dantzig, \n#        default is :bland\n#\n# The function returns:\n#     x_opt:  Decision variable values at the optimal solution\n#     f_opt:  Objective function value at the optimal solution\n#     x_hist: Decision variable values at each iteration\n#     c_hist: Reduced costs at each iteration\n#     B_hist: Column indices of the basic variables at each iteration\n#     iter:   Number of iterations before termination\n#\n# Usage: x_opt, f_opt, x_hist, c_hist, B_hist, iter = revised_simplex(A,b,c,B)\n\nfunction revised_simplex(A_orig, b_orig, c, B_ind_start; rule = :bland)\n    ## Error control\n    \n    ## If a constraint has negative RHS, multiply the constraint by -1\n    ## This way, b>=0\n    A = zeros(size(A_orig))\n    b = zeros(size(b_orig))\n    for i = 1:length(b_orig)\n        if b_orig[i] < 0\n            A[i,:] = -A_orig[i,:]\n            b[i] = -b_orig[i]\n        else\n            A[i,:] = A_orig[i,:]\n            b[i] = b_orig[i]\n        end\n    end\n\n    ## Check the keyword argument\n    if rule != :dantzig && rule != :bland\n         println(\"error: rule $(rule) not known, defaulting to Bland.\")\n         rule = :bland \n    end\n    \n    ## Initialization phase\n    \n    ## Initialize the vector of decision variables\n    x = zeros(length(c))\n    \n    ## Construct the basis matrix B according to the column indices of the basic\n    ## variables in B_ind and compute its inverse (denoted by invB)\n    B_ind = B_ind_start\n    B = zeros(length(B_ind), length(B_ind))\n    \n    B = A[:, B_ind]             # Basis matrix, take the columns of A with indices in B_ind\n    invB = inv(B)               # Inverse of the basis matrix\n    x[B_ind] = invB * b;        # Calculate x_B for initial basis\n\n    k_max = 50        # At most n_max iterations\n    k = 0             # Counter for the while loop\n    ϵ = 1E-9          # A small numerical tolerance, explained below: \n                      # Comparisons like x>=0 can fail if x=-1E-10,\n                      # when x is practically zero, with some numerical inaccuracy\n                      # You can try asking your computer if 0.1+0.2 == 0.3 holds \n\n    x_hist = zeros(k_max+1,length(x))\n    c_hist = zeros(k_max+1,length(c))\n    B_hist = zeros(k_max+1,length(B_ind))\n\n    ## Iteration phase\n    \n    cᵣ = calculate_cr(A, c, B_ind, invB)\n    update_history!(c_hist, cᵣ, x_hist, x, B_hist, B_ind, 1)\n    \n    while iteration_condition(cᵣ, ϵ)\n        @assert k<k_max \"Maximum number of iterations reached\"\n\n        B_ind, x, cᵣ, invB, returnflag = revised_simplex_iteration(A, c, B_ind, x, cᵣ, invB, rule, ϵ)\n        \n        k += 1                 # Increase counter\n        \n        if returnflag == -1    # Problem is unbounded\n            f_opt = \"-inf\"     # Optimal objective function cost = -inf\n            x_opt = []         # Produce empty vector []\n            return x_opt, f_opt, x_hist[1:k,:], c_hist[1:k,:], B_hist[1:k,:], k\n        else\n            update_history!(c_hist, cᵣ, x_hist, x, B_hist, B_ind, k+1)\n        end\n    end\n    \n    ## Optimal solution was found if we manage to break out of the while loop\n    f_opt = dot(c,x)        # Optimal objective function cost\n    x_opt = x               # Values of the decision variables in the optimum\n    return x_opt, f_opt, x_hist[1:k+1,:], c_hist[1:k+1,:], B_hist[1:k+1,:], k \nend;\n# End function"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two-phase simplex\nFinally, we can use this to implement the two-phase simplex method. Again, you only need to implement the parts with \"TODO\" -comments. In order to reduce the workload of this assignment, we do not consider the preprocessing for a degenerate auxiliary problem."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Implements a general two-phase simplex method. \n## Presumes that for feasible problems, all artificial variables are zero.\n\nfunction two_phase(A, b, c; rule=:bland)\n    \n    ## Augmenting problem to auxiliary form:\n    ## [0 1] [x z]'\n    ## [A Z] [x z]' = b\n    ## [x z] ≥ 0 \n    \n    m,n = size(A)\n    # TODO: add your code here\n    \n    ## Phase 1 problem\n    x_opt, f_opt, x_hist, c_hist, B_hist, k1 = revised_simplex(TODO: add your code here)\n\n    if !iszero(f_opt)                                       # Infeasible problem\n        println(\"error: Infeasible problem. z=$(f_opt).\")\n        f_opt = \"+inf\"\n        x_opt = []             \n        return x_opt, f_opt, x_hist, c_hist, B_hist, k1 \n    elseif any(j -> j > n, B_hist[k1+1,:])                  # Feasible but with basic artificial variable\n        println(\"warning: The problem is feasible, however the artificial var. x$(j) is basic in the optimal;\")\n        println(\"Revise the basis to remove it before calling revised_simplex() with obtained B_ind.\")\n        return x_opt, f_opt, x_hist, c_hist, B_hist, k1\n    else                                                    # Proceed to phase 2 \n        B_ind = convert.(Int64, B_hist[k1+1,:])                \n        x_opt, f_opt, x_hist, c_hist, B_hist, k2 = revised_simplex(TODO: add your code here)\n        return x_opt, f_opt, x_hist, c_hist, B_hist, k1+k2\n    end\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing your code\n\nYou can use the cells below to test your functions and see if you obtain the same result from Exercise 4.4 that was solved in the exercise session."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Test problem (Exercise 4.4)\n\n## Maximize 5x1 + x2\n## s.t.     2x1 + x2  >= 5\n##                x2  >= 1\n##          2x1 + 3x2 <= 12\n##           x1,   x2 >= 0\n\n## becomes\n\n## Minimize -5x1 -  x2\n## s.t.      2x1 +  x2 - x3           = 5\n##                  x2      - x4      = 1\n##           2x1 + 3x2           + x5 = 12\n##            x1,   x2,  x3,  x4,  x5 >= 0\n\n\nA = [2  1 -1  0  0;\n     0  1  0 -1  0;\n     2  3  0  0  1];\nb = [5, 1, 12];\nc = -[5, 1, 0, 0, 0];\n\nϵ = 1E-9\n\n# Basis was obtained from solving the auxiliary problem in the exercise, \n# these tests only consider the second phase\nB_ind = [1,2,4]\ninvB = inv(A[:,B_ind])\nx = [0.75, 3.5, 0.0, 2.5, 0.0]\n\nprintln(\"Initial basis is $(B_ind) with x equal to $(x)\\n\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Testing calculate_cr\ncᵣ = calculate_cr(A, c, B_ind, invB)\nprintln(\"Reduced costs are $(cᵣ)\")\nprintln(\"Should be         [0.0 0.0 -3.25 0.0 -0.75]\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Testing iteration_condition()\ncond = iteration_condition(cᵣ, ϵ)\nprintln(\"The smallest reduced cost is $(minimum(cᵣ)) and the algorithm \", if cond \"continues\" else \"terminates with an optimal solution\" end, \", should continue\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "J = findall(vec(cᵣ) .< -ϵ)       # We use vec(c_r) since findall is type sensitive and might return CartesianIndices instead.\n\n## Testing select_entering_variable()\nrule = :bland\nj_in = select_entering_variable(J, cᵣ, rule)\nprintln(\"Entering variable with Bland's rule is x_$(j_in), should be x_3\")\n\nrule = :dantzig\nj_in = select_entering_variable(J, cᵣ, rule)\nprintln(\"Entering variable with Dantzig's rule is x_$(j_in), should be x_3\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Testing calculate_reverse_basic_directions()\nu = calculate_reverse_basic_directions(A, invB, j_in)\nprintln(\"Reverse basic directions (the tableau column corresponding to the entering variable) are $(u), should be [-0.75, 0.5, 0.5]\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Ir = findall(vec(u) .> ϵ)\n\n## Testing calculate_step_length()\nθ = calculate_step_length(x, B_ind, u, Ir)\nprintln(\"Step length is $(θ), should be 5.0\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Testing select_leaving_variable()\nl_out = select_leaving_variable(B_ind, x, u, Ir, θ)\nprintln(\"Leaving variable is x_$(B_ind[l_out]) (row $(l_out) of the tableau), should be x_4 (row 3)\\n\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Testing update_x!()\nupdate_x!(x, j_in, B_ind, θ, u)\nprintln(\"New vector x is $(x)\")\nprintln(\"Should be       [4.5, 1.0, 5.0, 0.0, 0.0]\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Testing update_B_ind!()\nupdate_B_ind!(B_ind, l_out, j_in)\nprintln(\"New basis is $(B_ind)\")\nprintln(\"Should be    [1, 2, 3]\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## Testing update_invB!()\nupdate_invB!(invB, u, l_out)\nprintln(\"New invB is \", invB)\nprintln(\"Should be   \", [0.0 -1.5 0.5; 0.0 1.0 0.0; -1.0 -2.0 1.0], \"\\n\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "cᵣ = calculate_cr(A, c, B_ind, invB)\nprintln(\"Reduced costs are $(cᵣ)\")\nprintln(\"Should be         [0.0 0.0 0.0 6.5 2.5]\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "cond = iteration_condition(cᵣ, ϵ)\nprintln(\"The smallest reduced cost is $(minimum(cᵣ)) and the algorithm \", if cond \"continues\" else \"terminates with an optimal solution\" end, \", should terminate\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "x_opt, f_opt, x_hist, c_hist, B_hist, k = revised_simplex(A, b, c, [1,2,4]);\nx_opt, f_opt, x_hist, c_hist, B_hist, k1 = two_phase(A, b, c)\nx_opt, f_opt, x_hist, c_hist, B_hist, k2 = two_phase(A, b, c, rule=:dantzig)\n\n# It should print (3, 4, [4.5, 1.0, 5.0, 0.0, 0.0], 23.5)\n(k1, k2, x_opt, -f_opt)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Item 3.a\n# TODO: add your code here"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Item 3.b\n# TODO: add your code here"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Item 3.c\n# TODO: add your code here"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.5.1"
    },
    "kernelspec": {
      "name": "julia-1.5",
      "display_name": "Julia 1.5.1",
      "language": "julia"
    }
  },
  "nbformat": 4
}
